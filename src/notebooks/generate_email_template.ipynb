{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Required Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743639578683
        }
      },
      "outputs": [],
      "source": [
        "# Installs OpenAI directly into the current kernel (not subprocess)\n",
        "!{sys.executable} -m pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743639578898
        }
      },
      "outputs": [],
      "source": [
        "# Installs computer vision directly into the current kernel\n",
        "!{sys.executable} -m pip install azure-cognitiveservices-vision-computervision --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743639580836
        }
      },
      "outputs": [],
      "source": [
        "pip install azure-ai-inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Required Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743639582249
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "from azureml.core import Workspace, Datastore\n",
        "from typing import Dict, Any, List\n",
        "from azure.ai.inference.models import SystemMessage, UserMessage\n",
        "\n",
        "# Azure OpenAI client\n",
        "from azure.ai.inference import ChatCompletionsClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "# Computer Vision Client\n",
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743639582669
        }
      },
      "outputs": [],
      "source": [
        "# Confirm version\n",
        "print(\"OpenAI SDK version:\", openai.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Download JSON template locally from datastore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743639583872
        }
      },
      "outputs": [],
      "source": [
        "# Connect to the workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Get the datastore\n",
        "datastore = Datastore.get(ws, datastore_name='testdata')\n",
        "if datastore is None:\n",
        "    print(\"Datastore not found.\")\n",
        "    sys.exit(1)\n",
        "else:\n",
        "    print(f\"Found the datastore: {datastore}\")\n",
        "    file_path = 'data/jsons/email_template.json'  # path inside the datastore\n",
        "\n",
        "    # Download the JSON file to a local path\n",
        "    print(\"Preparing to download JSON file from datastore...\")\n",
        "    # Create download folder\n",
        "    download_dir = './downloaded_jsons'\n",
        "    os.makedirs(download_dir, exist_ok=True)\n",
        "    # Download the file from the datastore\n",
        "    try:\n",
        "        print(f\"Downloading {file_path} to {download_dir}...\")\n",
        "        datastore.download(target_path=download_dir, prefix=file_path, overwrite=True)\n",
        "        print(f\"Download complete. File saved to {download_dir}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during download: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Read the JSON file\n",
        "    local_file_path = os.path.join(download_dir, file_path)\n",
        "    with open(local_file_path, 'r') as f:\n",
        "        email_json = json.load(f)\n",
        "\n",
        "    # Print the data\n",
        "    print(json.dumps(email_json, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Download images locally from datastore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743639584151
        }
      },
      "outputs": [],
      "source": [
        "image_dir_path = 'data/images'\n",
        "temp_image_dir = './downloaded_images'\n",
        "os.makedirs(temp_image_dir, exist_ok=True)\n",
        "\n",
        "# Download all image files from image directory\n",
        "datastore.download(\n",
        "    target_path=temp_image_dir,\n",
        "    prefix=image_dir_path,\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "# List downloaded image files\n",
        "image_files = []\n",
        "for root, _, files in os.walk(temp_image_dir):\n",
        "    for file in files:\n",
        "        image_files.append(os.path.join(root, file))\n",
        "\n",
        "print(f\"Found {len(image_files)} image files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Setup Azure OpenAI Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743639584323
        }
      },
      "outputs": [],
      "source": [
        "# Initialize Azure OpenAI client\n",
        "openai_client = ChatCompletionsClient(\n",
        "    endpoint=\"https://aisgenaipoctlnx.services.ai.azure.com/models\",\n",
        "    credential=AzureKeyCredential(\"KEY_HERE\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Setup Azure Computer Vision Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743639584476
        }
      },
      "outputs": [],
      "source": [
        "# Initialize Azure Computer Vision Client\n",
        "vision_client = ComputerVisionClient(\n",
        "    endpoint=\"https://aisgenaipoctlnx.cognitiveservices.azure.com/\", \n",
        "    credentials=CognitiveServicesCredentials(\"KEY_HERE\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Process, map images and generate new JSON with mapped images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743639604451
        }
      },
      "outputs": [],
      "source": [
        "IMAGE_BASE_URL = \"<REPLACE WITH YOUR IMAGE BASE URL>\"  # e.g., \"https://yourstorageaccount.blob.core.windows.net/images/\"\n",
        "\n",
        "def load_json(file_path: str) -> Dict[str, Any]:\n",
        "    with open(file_path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def list_images(image_directory: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    List all image filenames in the provided directory, filtering only valid image types.\n",
        "    \"\"\"\n",
        "    valid_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff'}\n",
        "    \n",
        "    # Return only files with valid image extensions\n",
        "    return [\n",
        "        f for f in os.listdir(image_directory)\n",
        "        if os.path.isfile(os.path.join(image_directory, f)) and os.path.splitext(f)[1].lower() in valid_extensions\n",
        "    ]\n",
        "\n",
        "def analyze_image(image_path: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Analyze an image using Azure Computer Vision and return relevant features.\n",
        "    \"\"\"\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        analysis = vision_client.analyze_image_in_stream(\n",
        "            image_file,\n",
        "            visual_features=[\n",
        "                VisualFeatureTypes.description,\n",
        "                VisualFeatureTypes.tags,\n",
        "                VisualFeatureTypes.objects,\n",
        "                VisualFeatureTypes.brands,\n",
        "                VisualFeatureTypes.color,\n",
        "                VisualFeatureTypes.categories \n",
        "            ]\n",
        "        )\n",
        "    \n",
        "    result = {\n",
        "        \"description\": analysis.description.captions[0].text if analysis.description.captions else \"\",\n",
        "        \"tags\": [tag.name for tag in analysis.tags],\n",
        "        \"brands\": [brand.name for brand in analysis.brands],\n",
        "        \"objects\": [obj.object_property for obj in analysis.objects],\n",
        "        \"color\": analysis.color.dominant_colors\n",
        "    }\n",
        "    return result\n",
        "\n",
        "def extract_image_features(image_directory: str) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Extract features from all images in a directory.\n",
        "    \"\"\"\n",
        "    image_features = {}\n",
        "    for image_name in list_images(image_directory):\n",
        "        image_path = os.path.join(image_directory, image_name)\n",
        "        print(f\"Analyzing image: {image_name}\")\n",
        "        image_features[image_name] = analyze_image(image_path)\n",
        "    return image_features\n",
        "\n",
        "def match_image(section_description: str, section_tags: List[str], image_features: Dict[str, Dict[str, Any]]) -> str:\n",
        "    \"\"\"\n",
        "    Use GPT-4o to match the most appropriate image file based on description, tags, and extracted image features.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an image matching assistant. Your task is to match an image with the following description and tags.\\n\"\n",
        "        f\"Description: {section_description}\\n\"\n",
        "        f\"Tags: {', '.join(section_tags)}\\n\"\n",
        "        f\"Below is the list of available images with their extracted features.\\n\\n\"\n",
        "        f\"{json.dumps(image_features, indent=2)}\\n\\n\"\n",
        "        f\"Identify the most relevant image filename and return it. Only return the filename.\"\n",
        "    )\n",
        "\n",
        "    response = openai_client.complete(\n",
        "        messages=[\n",
        "            SystemMessage(content=\"You assist with mapping descriptions to appropriate images.\"),\n",
        "            UserMessage(content=prompt),\n",
        "        ],\n",
        "        model=\"gpt-4o\",\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "    result = response.choices[0].message[\"content\"].strip()\n",
        "    print(f\"** Matched Image: {result}\")\n",
        "    return result\n",
        "\n",
        "def map_images_to_sections(sections: Dict[str, Any], image_features: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Create a new JSON object with images mapped to sections and include URLs under the correct image key.\n",
        "    This function dynamically finds keys related to images like 'logo_image', 'qr_image', 'image', or any key ending with '_image'.\n",
        "    It also traverses nested structures such as rows and columns.\n",
        "    \"\"\"\n",
        "    new_json = {\"email_template\": {\"sections\": {}}}\n",
        "    description_pattern = re.compile(r'.*_description$')  # Matches keys ending with '_description'\n",
        "    image_key_pattern = re.compile(r'.*(_image|^image)$')  # Matches keys ending with '_image' and 'image'\n",
        "\n",
        "    def process_section_content(section_content):\n",
        "        \"\"\"\n",
        "        Recursively process the section content to find image-related keys and update them with image URLs.\n",
        "        \"\"\"\n",
        "        if isinstance(section_content, dict):\n",
        "            for key, value in section_content.items():\n",
        "                \n",
        "                # If it's a list (rows or columns) iterate over the items\n",
        "                if isinstance(value, list):\n",
        "                    for item in value:\n",
        "                        process_section_content(item)\n",
        "                \n",
        "                # Check if the key is an image-related key\n",
        "                if image_key_pattern.match(key):\n",
        "                    print(f\"Processing Image Key: {key}\")\n",
        "                    found_tags = value.get('tags', [])\n",
        "                    found_description = None\n",
        "\n",
        "                    # Find the description key\n",
        "                    for sub_key, sub_value in value.items():\n",
        "                        if description_pattern.match(sub_key):\n",
        "                            found_description = sub_value\n",
        "                            break\n",
        "\n",
        "                    # If description or tags are found, attempt to match with an image\n",
        "                    if found_tags or found_description:\n",
        "                        description = found_description if found_description else \"\"\n",
        "                        tags = found_tags if found_tags else []\n",
        "\n",
        "                        matched_image = match_image(description, tags, image_features)\n",
        "                        \n",
        "                        if matched_image:\n",
        "                            # Clean up the image name and build the URL\n",
        "                            matched_image = matched_image.strip().replace('\"', '').replace(\"\\\\\", \"\")\n",
        "                            image_url = f\"{IMAGE_BASE_URL}{matched_image}\"\n",
        "                            \n",
        "                            # Add the image_url to the image key\n",
        "                            section_content[key]['image_url'] = image_url\n",
        "                            print(f\"Mapped image '{matched_image}' to '{key}' with URL: {image_url}\")\n",
        "\n",
        "    # Process each section in the original JSON\n",
        "    for section_name, section_content in sections.items():\n",
        "        if isinstance(section_content, dict):\n",
        "            print(f\"\\nProcessing Section: {section_name}\")\n",
        "            new_section_content = section_content.copy()  # Make a copy to avoid modifying the original JSON\n",
        "            \n",
        "            # Process rows and columns if they exist\n",
        "            if 'rows' in new_section_content:\n",
        "                for row in new_section_content['rows']:\n",
        "                    if 'columns' in row:\n",
        "                        for column in row['columns']:\n",
        "                            process_section_content(column)\n",
        "            else:\n",
        "                process_section_content(new_section_content)\n",
        "            \n",
        "            new_json[\"email_template\"][\"sections\"][section_name] = new_section_content\n",
        "\n",
        "    return new_json\n",
        "\n",
        "\n",
        "# ------ Main Execution ------ # \n",
        "\n",
        "# Load JSON\n",
        "json_data = load_json(\"./downloaded_jsons/data/jsons/email_template.json\")\n",
        "\n",
        "# Extract image features using Azure Computer Vision\n",
        "image_directory = \"./downloaded_images/data/images\"\n",
        "image_features = extract_image_features(image_directory)\n",
        "\n",
        "# Split JSON into sections\n",
        "original_sections = json_data.get(\"email_template\", {}).get(\"sections\", {})\n",
        "\n",
        "# Map images to JSON sections\n",
        "new_json_with_images = map_images_to_sections(original_sections, image_features)\n",
        "\n",
        "# Save the new JSON file with image mappings\n",
        "new_json_path = \"./generated_template_with_images.json\"\n",
        "with open(new_json_path, \"w\") as f:\n",
        "    json.dump(new_json_with_images, f, indent=2)\n",
        "    print(f\"New JSON file with image mappings saved to: {new_json_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Generate final HTML email template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743640134001
        }
      },
      "outputs": [],
      "source": [
        "def load_json(file_path: str) -> Dict[str, Any]:\n",
        "    with open(file_path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def split_json_into_sections(json_data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Split the JSON structure into separate sections for individual processing.\n",
        "    \"\"\"\n",
        "    sections = json_data.get(\"email_template\", {}).get(\"sections\", {})\n",
        "    return sections\n",
        "\n",
        "def generate_prompt(section_name: str, section_content: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Create a prompt for GPT-4o to generate HTML from a specific JSON section.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an expert HTML template generator.\\n\"\n",
        "        f\"The following JSON structure defines the layout, sections, and content of an HTML email template.\\n\"\n",
        "        f\"Generate a clean, mobile-responsive HTML email based on this JSON.\\n\"\n",
        "        f\"Do NOT include <!DOCTYPE html>, <html>, <head>, or <body> tags.\\n\"\n",
        "        f\"Generate only the HTML content for the section, without any code block markers or markdown formatting.\\n\"\n",
        "        f\"Ensure all text, images, and structural components are included exactly as defined in the JSON.\\n\"\n",
        "        f\"IMPORTANT:\\n\"\n",
        "        f\"- If an image section has an 'image_url', only include the <img> tag with that URL.\\n\"\n",
        "        f\"- Ignore all 'description', 'tags', or other metadata related to the image if 'image_url' is present.\\n\"\n",
        "        f\"- Maintain the structural integrity of rows and columns:\\n\"\n",
        "        f\"  - Each row can contain multiple columns.\\n\"\n",
        "        f\"  - Each column may contain a combination of images, titles, and paragraph text.\\n\"\n",
        "        f\"  - Ensure that all elements within a column are grouped together within the same column div.\\n\"\n",
        "        f\"  - Do NOT separate titles, paragraphs, or images that are part of the same column.\\n\"\n",
        "        f\"  - Respect the layout hierarchy and ensure that content from a single column is not split into multiple columns.\\n\"\n",
        "        f\"- Do NOT generate HTML content for 'description' or 'tags'.\\n\"\n",
        "        f\"Section Name: {section_name}\\n\"\n",
        "        f\"JSON Data:\\n{json.dumps(section_content, indent=2)}\"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "def call_gpt4o(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Call the GPT-4o model in Azure OpenAI to generate HTML from a given prompt.\n",
        "    \"\"\"\n",
        "    # Call GPT-4o on Azure OpenAI\n",
        "    response = openai_client.complete(\n",
        "        messages=[\n",
        "            SystemMessage(content=\"You generate responsive HTML email templates.\"),\n",
        "            UserMessage(content=prompt),\n",
        "        ],\n",
        "        model=\"gpt-4o\",\n",
        "        temperature=0.2\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"].strip()\n",
        "\n",
        "def process_sections(sections: Dict[str, Any]) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Process each section of the JSON and generate HTML using GPT-4o.\n",
        "    \"\"\"\n",
        "    html_sections = {}\n",
        "    for section_name, section_content in sections.items():\n",
        "        print(f\"Processing section: {section_name}\")\n",
        "        \n",
        "        prompt = generate_prompt(section_name, section_content)\n",
        "        html_output = call_gpt4o(prompt)\n",
        "        \n",
        "        # Remove unwanted tags if they appear\n",
        "        html_output = html_output.replace(\"<!DOCTYPE html>\", \"\").replace(\"<html>\", \"\").replace(\"</html>\", \"\")\n",
        "        html_output = html_output.replace(\"<head>\", \"\").replace(\"</head>\", \"\").replace(\"<body>\", \"\").replace(\"</body>\", \"\")\n",
        "        \n",
        "        html_sections[section_name] = html_output.strip()\n",
        "        print(f\"Completed section: {section_name}\\n\")\n",
        "    \n",
        "    return html_sections\n",
        "\n",
        "def combine_html_sections(html_sections: Dict[str, str]) -> str:\n",
        "    \"\"\"\n",
        "    Combine all HTML parts into a single email template.\n",
        "    \"\"\"\n",
        "    html_content = \"\".join([html for html in html_sections.values()])\n",
        "    print(html_content)\n",
        "\n",
        "    final_html = f\"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "    <head>\n",
        "        <meta charset=\"UTF-8\">\n",
        "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "        <title>Email Template</title>\n",
        "        <style>\n",
        "            body {{ font-family: Arial, sans-serif; }}\n",
        "            .container {{ width: 100%; max-width: 600px; margin: auto; }}\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <div class=\"container\">\n",
        "            {html_content}\n",
        "        </div>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "    return final_html\n",
        "\n",
        "def save_html(html_content: str, output_file: str):\n",
        "    \"\"\"\n",
        "    Save the final HTML content to a file.\n",
        "    \"\"\"\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(html_content)\n",
        "    print(f\"HTML email template saved to {output_file}\")\n",
        "\n",
        "# ------ Main Execution ------ #\n",
        "\n",
        "# Load JSON\n",
        "json_data = load_json(\"./generated_template_with_images.json\")\n",
        "\n",
        "# Split JSON into sections\n",
        "sections = split_json_into_sections(json_data)\n",
        "\n",
        "# Process each section and generate HTML\n",
        "html_sections = process_sections(sections)\n",
        "\n",
        "# Combine all sections into a single HTML template\n",
        "final_html = combine_html_sections(html_sections)\n",
        "\n",
        "# Save to file\n",
        "save_html(final_html, \"generated_email.html\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Display HTML Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1743640138064
        }
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "file_path = './generated_email.html'\n",
        "with open(file_path, 'r') as html_file:\n",
        "    html_content = html_file.read()\n",
        "\n",
        "display(HTML(html_content))"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
